2025-04-14 18:19:49,116 - INFO - [1228] - root - Initializing application
2025-04-14 18:19:49,116 - INFO - [1228] - root - Starting Flask server on port 8586
2025-04-14 18:19:49,143 - WARNING - [1228] - werkzeug -  * Debugger is active!
2025-04-14 18:19:49,152 - INFO - [1228] - werkzeug -  * Debugger PIN: 137-071-496
2025-04-14 18:20:24,430 - INFO - [1228] - root - Received upload request
2025-04-14 18:20:24,433 - INFO - [1228] - root - Upload parameters: language=ar ,conversational mode=True
2025-04-14 18:20:24,434 - INFO - [1228] - root - File saved to uploads/ad0721f3751f459e9deab81dbabe1dd2.m4a
2025-04-14 18:20:24,434 - INFO - [1228] - root - Starting batch processing mode
2025-04-14 18:20:24,434 - INFO - [1228] - src.services.audio_service - File saved: uploads/ad0721f3751f459e9deab81dbabe1dd2.m4a
2025-04-14 18:20:27,066 - INFO - [1228] - src.services.audio_service - Splitting audio file /var/folders/9h/zs4mvmp91456_d2n2hqf6wzc0000gn/T/tmp89qpmdt_/processed_audio.wav into chunks of 100% of total duration
2025-04-14 18:20:27,076 - INFO - [1228] - src.services.audio_service - Created 1 audio chunks (each 100% of total duration)
2025-04-14 18:20:27,078 - INFO - [1228] - src.services.audio_service - Processing audio chunk: /var/folders/9h/zs4mvmp91456_d2n2hqf6wzc0000gn/T/tmp89qpmdt_/processed_audio.wav_chunk_0.wav
2025-04-14 18:20:27,078 - INFO - [1228] - src.services.audio_service - Preprocessing chunk /var/folders/9h/zs4mvmp91456_d2n2hqf6wzc0000gn/T/tmp89qpmdt_/processed_audio.wav_chunk_0.wav
2025-04-14 18:20:32,397 - INFO - [1228] - groq._base_client - Retrying request to /openai/v1/audio/transcriptions in 0.464788 seconds
2025-04-14 18:20:40,108 - INFO - [1228] - httpx - HTTP Request: POST https://api.groq.com/openai/v1/audio/transcriptions "HTTP/1.1 200 OK"
2025-04-14 18:20:40,114 - INFO - [1228] - src.services.audio_service - Removed preprocessed chunk /var/folders/9h/zs4mvmp91456_d2n2hqf6wzc0000gn/T/tmpjffwckat/processed_audio.wav
2025-04-14 18:20:40,115 - INFO - [1228] - src.services.audio_service - Removed chunk /var/folders/9h/zs4mvmp91456_d2n2hqf6wzc0000gn/T/tmp89qpmdt_/processed_audio.wav_chunk_0.wav
2025-04-14 18:20:40,116 - INFO - [1228] - src.services.llm_service - Calling LLM API with model: accounts/fireworks/models/llama4-maverick-instruct-basic
2025-04-14 18:20:42,602 - INFO - [1228] - httpx - HTTP Request: POST https://api.fireworks.ai/inference/v1/completions "HTTP/1.1 200 OK"
2025-04-14 18:20:42,606 - INFO - [1228] - src.services.llm_service - Calling LLM API with model: accounts/fireworks/models/llama4-maverick-instruct-basic
2025-04-14 18:20:58,110 - ERROR - [1228] - src.services.llm_service - LLM API call failed: [Errno 54] Connection reset by peer
2025-04-14 18:20:58,111 - ERROR - [1228] - src.services.audio_service - Error in batch processing: LLM processing failed: [Errno 54] Connection reset by peer
Traceback (most recent call last):
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 156, in _connect
    stream = stream.start_tls(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpcore/_backends/sync.py", line 154, in start_tls
    with map_exceptions(exc_map):
  File "/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 54] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/muhammedamr/Desktop/AHBS/Voice recognition/src/services/llm_service.py", line 59, in _call_llm_api
    response = fireworks.client.Completion.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/fireworks/client/base_completion.py", line 81, in create
    return cls._create_non_streaming(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/fireworks/client/base_completion.py", line 180, in _create_non_streaming
    response = client.post_request_non_streaming(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/fireworks/client/api_client.py", line 159, in post_request_non_streaming
    response = self._client.post(
               ^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_client.py", line 1144, in post
    return self.request(
           ^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_client.py", line 825, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 54] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/muhammedamr/Desktop/AHBS/Voice recognition/src/services/audio_service.py", line 58, in process_batch
    translated_text = LLMService.translate_to_eng(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Voice recognition/src/services/llm_service.py", line 19, in translate_to_eng
    return LLMService.process_text(refined_text, api_key, model, "translate", conversational_mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Voice recognition/src/services/llm_service.py", line 81, in process_text
    result = LLMService._call_llm_api(api_key, model_account, prompt)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Voice recognition/src/services/llm_service.py", line 73, in _call_llm_api
    raise Exception(f"LLM processing failed: {str(e)}")
Exception: LLM processing failed: [Errno 54] Connection reset by peer
2025-04-14 18:20:58,129 - ERROR - [1228] - root - Error in batch processing: LLM processing failed: [Errno 54] Connection reset by peer
Traceback (most recent call last):
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_transports/default.py", line 101, in map_httpcore_exceptions
    yield
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_transports/default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 256, in handle_request
    raise exc from None
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    raise exc
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpcore/_sync/connection.py", line 156, in _connect
    stream = stream.start_tls(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpcore/_backends/sync.py", line 154, in start_tls
    with map_exceptions(exc_map):
  File "/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 54] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/muhammedamr/Desktop/AHBS/Voice recognition/src/services/llm_service.py", line 59, in _call_llm_api
    response = fireworks.client.Completion.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/fireworks/client/base_completion.py", line 81, in create
    return cls._create_non_streaming(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/fireworks/client/base_completion.py", line 180, in _create_non_streaming
    response = client.post_request_non_streaming(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/fireworks/client/api_client.py", line 159, in post_request_non_streaming
    response = self._client.post(
               ^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_client.py", line 1144, in post
    return self.request(
           ^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_client.py", line 825, in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_transports/default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/Users/muhammedamr/Desktop/AHBS/Refined_whisper/venv/lib/python3.11/site-packages/httpx/_transports/default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 54] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/muhammedamr/Desktop/AHBS/Voice recognition/test.py", line 84, in upload
    response = AudioService.process_batch(file_path, language, model, conversational_mode)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Voice recognition/src/services/audio_service.py", line 58, in process_batch
    translated_text = LLMService.translate_to_eng(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Voice recognition/src/services/llm_service.py", line 19, in translate_to_eng
    return LLMService.process_text(refined_text, api_key, model, "translate", conversational_mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Voice recognition/src/services/llm_service.py", line 81, in process_text
    result = LLMService._call_llm_api(api_key, model_account, prompt)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/muhammedamr/Desktop/AHBS/Voice recognition/src/services/llm_service.py", line 73, in _call_llm_api
    raise Exception(f"LLM processing failed: {str(e)}")
Exception: LLM processing failed: [Errno 54] Connection reset by peer
2025-04-14 18:20:58,138 - INFO - [1228] - werkzeug - 127.0.0.1 - - [14/Apr/2025 18:20:58] "[35m[1mPOST /upload HTTP/1.1[0m" 500 -
2025-04-14 18:21:06,995 - INFO - [1228] - root - Received upload request
2025-04-14 18:21:07,002 - INFO - [1228] - root - Upload parameters: language=ar ,conversational mode=True
2025-04-14 18:21:07,004 - INFO - [1228] - root - File saved to uploads/68744a089c8d4d2b95087970e1806e49.m4a
2025-04-14 18:21:07,004 - INFO - [1228] - root - Starting batch processing mode
2025-04-14 18:21:07,004 - INFO - [1228] - src.services.audio_service - File saved: uploads/68744a089c8d4d2b95087970e1806e49.m4a
2025-04-14 18:21:07,570 - INFO - [1228] - src.services.audio_service - Splitting audio file /var/folders/9h/zs4mvmp91456_d2n2hqf6wzc0000gn/T/tmpyg6mlpnh/processed_audio.wav into chunks of 100% of total duration
2025-04-14 18:21:07,578 - INFO - [1228] - src.services.audio_service - Created 1 audio chunks (each 100% of total duration)
2025-04-14 18:21:07,579 - INFO - [1228] - src.services.audio_service - Processing audio chunk: /var/folders/9h/zs4mvmp91456_d2n2hqf6wzc0000gn/T/tmpyg6mlpnh/processed_audio.wav_chunk_0.wav
2025-04-14 18:21:07,579 - INFO - [1228] - src.services.audio_service - Preprocessing chunk /var/folders/9h/zs4mvmp91456_d2n2hqf6wzc0000gn/T/tmpyg6mlpnh/processed_audio.wav_chunk_0.wav
2025-04-14 18:21:15,114 - INFO - [1228] - httpx - HTTP Request: POST https://api.groq.com/openai/v1/audio/transcriptions "HTTP/1.1 200 OK"
2025-04-14 18:21:15,118 - INFO - [1228] - src.services.audio_service - Removed preprocessed chunk /var/folders/9h/zs4mvmp91456_d2n2hqf6wzc0000gn/T/tmpy90pujcw/processed_audio.wav
2025-04-14 18:21:15,119 - INFO - [1228] - src.services.audio_service - Removed chunk /var/folders/9h/zs4mvmp91456_d2n2hqf6wzc0000gn/T/tmpyg6mlpnh/processed_audio.wav_chunk_0.wav
2025-04-14 18:21:15,121 - INFO - [1228] - src.services.llm_service - Calling LLM API with model: accounts/fireworks/models/llama4-maverick-instruct-basic
2025-04-14 18:21:19,597 - INFO - [1228] - httpx - HTTP Request: POST https://api.fireworks.ai/inference/v1/completions "HTTP/1.1 200 OK"
2025-04-14 18:21:19,602 - INFO - [1228] - src.services.llm_service - Calling LLM API with model: accounts/fireworks/models/llama4-maverick-instruct-basic
2025-04-14 18:21:22,380 - INFO - [1228] - httpx - HTTP Request: POST https://api.fireworks.ai/inference/v1/completions "HTTP/1.1 200 OK"
2025-04-14 18:21:22,386 - INFO - [1228] - src.services.llm_service - Calling LLM API with model: accounts/fireworks/models/llama4-maverick-instruct-basic
2025-04-14 18:21:26,577 - INFO - [1228] - httpx - HTTP Request: POST https://api.fireworks.ai/inference/v1/completions "HTTP/1.1 200 OK"
2025-04-14 18:21:26,593 - INFO - [1228] - werkzeug - 127.0.0.1 - - [14/Apr/2025 18:21:26] "POST /upload HTTP/1.1" 200 -
2025-04-14 18:22:17,942 - INFO - [1228] - werkzeug -  * Detected change in '/Users/muhammedamr/Desktop/AHBS/Voice recognition/src/services/audio_service.py', reloading
